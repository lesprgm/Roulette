# ğŸ² Nonâ€‘Deterministic Website

<div align="center">

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.116+-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

**âœ¨ Generate unique, interactive mini-sites with AI â€” one click, infinite possibilities**

</div>

---

A tiny FastAPI app that prompts an LLM to generate exactly one selfâ€‘contained interactive web app per request and renders it safely inside a sandboxed iframe. It emphasizes instant, meaningful interaction (clear controls, visible effects) and enforces strict output and sandbox rules.

### ğŸ“¸ Demo

<div align="center">

![Homepage](https://github.com/user-attachments/assets/a8f525a1-d669-4376-a3d9-cdb65974eeac)

*Click "Generate" to conjure a brand-new interactive mini-site*

![Generated Example](https://github.com/user-attachments/assets/368ed89f-c06d-4a6c-9734-a947509882e7)

*Example: A "Guess the Number" game generated on-the-fly*

</div>

---

## ğŸ”„ How it works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User clicks â”‚
â”‚  Generate   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prefetch Queue? â”‚â”€Yesâ”€â†’â”‚ Dequeue page â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         No                     â”‚
         â”‚                      â”‚
         â–¼                      â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
  â”‚ Call LLM â”‚                 â”‚
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â”‚
        â”‚                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Render in      â”‚
          â”‚ sandboxed      â”‚
          â”‚ iframe         â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Increment      â”‚
          â”‚ counter        â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Display site   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ Request â†’ Generation
- **POST** `/generate` accepts an optional `brief` and `seed`
- Server first tries to serve a **prefetched page** (dequeueâ€‘first approach)
- If serving from prefetch, simulates LLM latency with a small configurable delay
- On success, a persistent counter increments; the UI shows a floating **"Sites generated"** badge from `/metrics/total`

### ğŸ“¦ Prefetch queue
- **Diskâ€‘backed FIFO** at `cache/prefetch/`
- Fill endpoint asks the LLM for **5â€“10 pages** and enqueues them (LLMâ€‘only; no offline prefetch)
- **Background topâ€‘up**: when the queue is low, the server refills in the background (guarded by env flags)
- **Dedupe**: a signature registry avoids recent repeats; duplicates prompt a retry with a nudged seed

### ğŸ”’ Output constraints and safety
- LLM must return JSON in one of two shapes: a single `{kind:"full_page_html"}` document or a single custom component with inline HTML/JS
- Frontend **strips external `<script src>` tags** and runs only inline JS in a **sandboxed iframe** with a strict CSP
- Iframe autoâ€‘resizes and autoâ€‘focuses so keyboard input works immediately

---

## ğŸš€ Quickstart

**Prerequisites:** Python 3.10+ and pip. (Node is optional; a prebuilt `static/tailwind.css` is used in dev.)

```bash
# 1ï¸âƒ£ Set up virtual environment
python -m venv venv
source venv/bin/activate

# 2ï¸âƒ£ Install dependencies
pip install -r requirements.txt
# or: pip install fastapi uvicorn requests pydantic jsonschema ndjson

# 3ï¸âƒ£ Run the API (dev reload)
uvicorn api.main:app --reload --port 8000
```

**ğŸŒ Open** http://127.0.0.1:8000/ for the demo UI.

### ğŸ”‘ API Configuration

Put provider keys in `.env` (autoâ€‘loaded):

```bash
OPENROUTER_API_KEY=sk-...
OPENROUTER_MODEL=google/gemma-3n-e2b-it:free
# optional: FORCE_OPENROUTER_ONLY=1
```

---

## ğŸŒ Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| **GET** | `/` | Demo UI |
| **GET** | `/health` | Health check: `{ "status": "ok" }` |
| **GET** | `/llm/status` | Provider/model/has_token without calling the model |
| **GET** | `/llm/probe` | Lightweight readiness probe |
| **GET** | `/metrics/total` | Global "sites generated" counter |
| **GET** | `/prefetch/status` | Current queue size and directory |
| **POST** | `/validate` | Validate a page structure |
| **POST** | `/generate` | Generate or dequeue a page (dedupe applied; counter increments) |
| **POST** | `/generate/stream` | NDJSON stream: `{event:"meta"}` then `{event:"page", data:{...}}` |
| **POST** | `/prefetch/fill` | Ask the LLM for N pages (5â€“10) and enqueue |

---

## âš™ï¸ Configuration (env)

### ğŸ¤– LLM provider (OpenRouter by default)
```bash
OPENROUTER_API_KEY=        # (required for live generation)
OPENROUTER_MODEL=          # default: google/gemma-3n-e2b-it:free
FORCE_OPENROUTER_ONLY=     # default: 0 â€” force OpenRouter path when set

# Optional Gemini:
GEMINI_API_KEY=            # or GOOGLE_API_KEY
MODEL_NAME=                # Gemini model name
```

### ğŸ¨ Generation
```bash
TEMPERATURE=               # default: 1.2
ALLOW_OFFLINE_GENERATION=  # dev only; affects /generate fallback, not prefetch
```

### ğŸ“¦ Prefetch
```bash
PREFETCH_DIR=              # default: cache/prefetch
PREFETCH_BATCH_MIN=        # default: 5
PREFETCH_BATCH_MAX=        # default: 10
PREFETCH_DELAY_MS=         # delay when serving dequeued pages
PREFETCH_LOW_WATER=        # trigger background refill threshold
PREFETCH_FILL_TO=          # target queue size for refill
PREFETCH_TOPUP_ENABLED=    # enable background top-up
```

### ğŸ” Dedupe
```bash
DEDUPE_ENABLED=            # default: 1
DEDUPE_MAX=                # max dedupe registry size
DEDUPE_RECENT_FILE=        # dedupe registry file path
```

### ğŸ” Access / CORS / rate limiting
```bash
API_KEYS=                  # commaâ€‘separated; if empty, local dev is open
ALLOW_ORIGINS=             # default: *
RATE_WINDOW_SECONDS=       # rate limit window
RATE_MAX_REQUESTS=         # max requests per window
```

---

## ğŸ§ª Development

Run tests:

```bash
pytest -q
```

The test suite covers:
- âœ… Prefetch queue (enqueue/dequeue, dedupe, fill clamping)
- âœ… Dequeueâ€‘first generation
- âœ… Background topâ€‘ups
- âœ… Status endpoints

> **Note:** During tests, artificial delays and background workers are disabled for speed and determinism.

---

## ğŸ“‹ Notes on generation rules

The prompt enforces strict quality and interactivity standards:

- âŒ **Strictly banned:** Passive visuals, randomizersâ€‘only, menuâ€‘only UIs, utility archetypes (calculators/clocks/toâ€‘dos/quizzes)
- âœ… **Classic/trivial miniâ€‘games allowed** but must meet the interactivity bar:
  - Clear controls
  - Visible feedback
  - Responsive interaction
- âœ… **Required features:**
  - Clear, immediate input â†’ effect loops
  - Obvious affordances
  - At least two input modes (mouse/touch + another)
  - Visible feedback

---

## ğŸ”§ Troubleshooting

| Issue | Solution |
|-------|----------|
| **Provider 429 rate limit** | Back off; prefetch masks transient spikes |
| **SSL/cert issues** | Ensure system trust/certifi is upâ€‘toâ€‘date; avoid disabling verification globally |
| **"Invalid JSON" from provider** | The server extracts the first JSON object and validates/normalizes it; try again or adjust temperature/model |

---

## ğŸ“„ License

MIT â€” see `LICENSE`.
